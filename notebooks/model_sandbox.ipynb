{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: to beat / get comparable to fb results, need R^2 values between 0.56 (spatial CV), 0.59 (leave country out), and 0.7 (conventional CV). They construct spatial CV as follows: \n",
    "\n",
    "    In each country, we select a random cell as the training centroid, then define the  training dataset as the nearest (k-1)/k percent of cells to that centroid. The remaining 1/k cells from that country form the test dataset. This procedure is repeated k times in each country.\n",
    "\n",
    "Importantly, they construct the ground truth in the first place carefully, to account for ~2km location jitter in urban areas, and ~5km jitter in rural areas: \n",
    "\n",
    "    To ensure that the input data associated with each village cover the villageâ€™s true location, we include a 2x2 grid of 2.4km cells around the centroid in urban areas, and a 4x4 grid in rural areas. For each of village, we then take the population-weighted average of the 112-dimensional feature vectors across 2x2 or 4x4 set of cells, using existing estimates of the population of 2.4km grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report as class_rep,\n",
    "    confusion_matrix as conf_mat,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from stc_unicef_cpi.models import lgbm_baseline as baseline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"/Users/johnf/Downloads/higher_res_dssg/\")\n",
    "all_data = base_dir / \"clean_nga_w_autov1.csv\"\n",
    "thr_data = base_dir / \"nga_clean_v2_thr30.csv\"\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(all_data)\n",
    "all_df['name_commuting_zone'] = all_df['name_commuting_zone'].astype('category')\n",
    "thr_df = pd.read_csv(thr_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[(name,val) for name,val in zip(all_df.isna().sum(axis=0).index,all_df.isna().sum(axis=0).values) if val > 5],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_norm = pd.read_csv(base_dir / \"autoencodings_norm.csv\",index_col=0)\n",
    "auto_norm.index.name = 'hex_code'\n",
    "auto_norm.columns = [f\"auto_norm_{i}\" for i in range(len(auto_norm.columns))]\n",
    "auto_unnorm = pd.read_csv(base_dir / \"autoencodings_unnorm.csv\",index_col=0)\n",
    "auto_unnorm.index.name = 'hex_code'\n",
    "auto_unnorm.columns = [f\"auto_unnorm_{i}\" for i in range(len(auto_unnorm.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop(columns=[col for col in all_df.columns if 'auto_' in col],inplace=True) \n",
    "all_df = all_df.join(auto_norm,on='hex_code',how='left').join(auto_unnorm,on='hex_code',how='left')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_all = all_df.set_index('hex_code').loc[thr_df.hex_code].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_all.to_csv(base_dir / \"new_auto_thr_clean_nga.csv\")\n",
    "thr_all.to_csv(\"../data/processed/new_auto_thr_clean_nga.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[(name,val) for name,val in zip(thr_all.nunique(axis=0).index,thr_all.nunique(axis=0).values) if val < 200],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB reduce resolution from ~100m x 100m squares to ~500m x 500m squares using average, then again \n",
    "# take average using centroids of pixels within hex boundaries. \n",
    "# Hence to get absolute population estimates, need to x (500/100)^2 for each 500m pixel, so x 25\n",
    "# then multiply again by average number of 500m pixels within hex, which is very roughly 5.16km^2 / (0.25)\n",
    "# ~ 20.64\n",
    "# abs pop of Nigeria is ~220M so should be decently less than this\n",
    "thr_all['abs_pop']=(thr_all.population*25*20.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pop_thr in np.linspace(50,500,10):\n",
    "    print(f\"{pop_thr:.0f}: {(thr_all.abs_pop<pop_thr).mean()*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = thr_df.columns.tolist().index(\"LATNUM\")\n",
    "X = thr_df.iloc[:, start_idx:]\n",
    "X[\"n_conflicts\"].fillna(0, inplace=True)\n",
    "sev_cols = [col for col in thr_df.columns if \"sev\" in col]\n",
    "Y = thr_df[sev_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_quants = 5\n",
    "quant_Y = pd.concat(\n",
    "    [\n",
    "        pd.cut(\n",
    "            Y[col],\n",
    "            np.linspace(0, 1, n_quants + 1),\n",
    "            labels=range(n_quants),\n",
    "            include_lowest=True,\n",
    "        ).astype(\"category\")\n",
    "        for col in Y.columns\n",
    "        if \"sum\" not in col\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[quant_Y.isna().sum(axis=1) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_Y.dropna().astype(int).hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_Y.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idxs = [\"housing\", \"water\", \"sanitation\", \"education\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "for chosen_idx in good_idxs:\n",
    "    qX_train, qX_test, qy_train, qy_test = train_test_split(\n",
    "        X,\n",
    "        quant_Y[chosen_idx.join([\"dep_\", \"_sev\"])],\n",
    "        test_size=test_size,\n",
    "        random_state=42,\n",
    "        stratify=quant_Y[chosen_idx.join([\"dep_\", \"_sev\"])],\n",
    "    )\n",
    "    # Initialize an AutoML instance\n",
    "    automl = AutoML()\n",
    "    # Specify automl goal and constraint\n",
    "    automl_settings = {\n",
    "        # \"time_budget\": 120,  # in seconds\n",
    "        \"metric\": \"micro_f1\",\n",
    "        \"task\": \"classification\",\n",
    "        \"log_file_name\": \"quint_v1.log\",\n",
    "        \"max_iter\": 500,\n",
    "        # \"ensemble\": {\n",
    "        #     \"final_estimator\": LogisticRegressionCV(),\n",
    "        #     \"passthrough\": False,\n",
    "        # },\n",
    "    }\n",
    "    # Train with labeled input data\n",
    "    mlflow.set_tracking_uri(\"../models/mlruns\")\n",
    "    mlflow.set_experiment(f\"flaml-automl-quint-{chosen_idx}\")\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.list_experiments()\n",
    "    # print(experiments)\n",
    "    exp_id = [\n",
    "        experiment.experiment_id\n",
    "        for experiment in experiments\n",
    "        if experiment.name == \"flaml-automl-quint\"\n",
    "    ][0]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # print(run.info.experiment_id)\n",
    "        automl.fit(X_train=qX_train, y_train=qy_train, **automl_settings)\n",
    "        # mlflow.sklearn.log_model(automl,\"automl-quint\")\n",
    "        # mlflow.log_params(automl.model.config2params())\n",
    "        mlflow.log_metric(\n",
    "            key=\"f1_score\",\n",
    "            value=f1_score(qy_test, automl.predict(qX_test), average=\"micro\"),\n",
    "        )\n",
    "    # Predict\n",
    "    # print(automl.predict_proba(qX_train))\n",
    "    # Print the best model\n",
    "    # print(automl.model.estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast as (quantile) classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    # \"time_budget\": 120,  # in seconds\n",
    "    \"metric\": \"micro_f1\",\n",
    "    \"task\": \"classification\",\n",
    "    \"log_file_name\": \"quint_v1.log\",\n",
    "    \"max_iter\": 500,\n",
    "    # \"ensemble\": {\n",
    "    #     \"final_estimator\": LogisticRegressionCV(),\n",
    "    #     \"passthrough\": False,\n",
    "    # },\n",
    "}\n",
    "# Train with labeled input data\n",
    "mlflow.set_tracking_uri(\"../models/mlruns\")\n",
    "mlflow.set_experiment(\"flaml-automl-quint\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiments = client.list_experiments()\n",
    "# print(experiments)\n",
    "exp_id = [\n",
    "    experiment.experiment_id\n",
    "    for experiment in experiments\n",
    "    if experiment.name == \"flaml-automl-quint\"\n",
    "][0]\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "    # print(run.info.experiment_id)\n",
    "    automl.fit(X_train=qX_train, y_train=qy_train, **automl_settings)\n",
    "    # mlflow.sklearn.log_model(automl,\"automl-quint\")\n",
    "    mlflow.log_metric(\n",
    "        f1_score(qy_test, automl.predict(qX_test), average=\"micro\"), \"f1_score\"\n",
    "    )\n",
    "# Predict\n",
    "# print(automl.predict_proba(qX_train))\n",
    "# Print the best model\n",
    "# print(automl.model.estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report as class_rep,\n",
    "    confusion_matrix as conf_mat,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "preds = automl.predict(qX_test)\n",
    "print(\n",
    "    class_rep(\n",
    "        qy_test,\n",
    "        preds,\n",
    "    )\n",
    ")\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "hmap = sns.heatmap(conf_mat(qy_test, preds), annot=True, fmt=\"d\")\n",
    "hmap.set_xlabel(\"Predicted\")\n",
    "hmap.set_ylabel(\"True\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with focal loss? See https://github.com/jrzaurin/LightGBM-with-Focal-Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast as ordinal classification / regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast as regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML (flaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    # \"time_budget\": 120,  # in seconds\n",
    "    \"metric\": \"r2\", #\"rmse\",\n",
    "    \"task\": \"regression\",\n",
    "    \"log_file_name\": \"reg_v1.log\",\n",
    "    \"max_iter\": 500,\n",
    "    # \"ensemble\": {\n",
    "    #     \"final_estimator\": LogisticRegressionCV(),\n",
    "    #     \"passthrough\": False,\n",
    "    # },\n",
    "}\n",
    "# Train with labeled input data\n",
    "for chosen_idx in good_idxs:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y[f\"dep_{chosen_idx}_sev\"], test_size=test_size, random_state=42\n",
    "    )\n",
    "    mlflow.set_tracking_uri(\"../models/mlruns\")\n",
    "    mlflow.set_experiment(f\"flaml-automl-{chosen_idx}-reg\")\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.list_experiments()\n",
    "    # print(experiments)\n",
    "    exp_id = [\n",
    "        experiment.experiment_id\n",
    "        for experiment in experiments\n",
    "        if experiment.name == f\"flaml-automl-{chosen_idx}-reg\"\n",
    "    ][0]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # print(run.info.experiment_id)\n",
    "        automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
    "        # mlflow.sklearn.log_model(automl,\"automl-quint\")\n",
    "        mlflow.log_param(key=\"best_model\", value=automl.best_estimator)\n",
    "        mlflow.log_params(automl.best_config)\n",
    "        mlflow.log_metric(\n",
    "            key=\"rmse\",\n",
    "            value=np.sqrt(mean_squared_error(y_test, automl.predict(X_test))),\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            key=\"r2_score\", value=r2_score(y_test, automl.predict(X_test))\n",
    "        )\n",
    "\n",
    "    preds = automl.predict(X_test)\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    scplot = sns.scatterplot(x=preds, y=y_test)\n",
    "    scplot.set_xlabel(\"Predicted\")\n",
    "    scplot.set_ylabel(\"True\")\n",
    "    scplot.set_title(chosen_idx)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM model + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chosen_idx in good_idxs:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y[chosen_idx.join([\"dep_\", \"_sev\"])], test_size=test_size, random_state=42\n",
    "    )\n",
    "    model, loss = baseline.lgbmreg_optunaCV(\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        target_name=chosen_idx,\n",
    "        experiment_name=f\"lgbm-opt-{chosen_idx}\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y.hist(bins=20,density=True)\n",
    "plt.show()\n",
    "for col in Y.columns:\n",
    "    # sns.distplot(np.log(Y[col]+1),bins=20,kde=False)\n",
    "    sns.distplot(Y[col], bins=20, kde=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "qX_resamp, qy_resamp = smote_enn.fit_resample(qX_train, qy_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAML reg on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols = [col for col in thr_all.columns if \"sev\" in col]\n",
    "good_cols = [col for col in sev_cols if 'health' not in col and 'nutrition' not in col]\n",
    "good_names = [col.replace('dep_','').replace('_sev','') for col in good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = thr_all.columns.tolist().index(\"LATNUM\")\n",
    "X = thr_all.iloc[:, start_idx:]\n",
    "sev_cols = [col for col in thr_all.columns if \"sev\" in col]\n",
    "Y = thr_all[sev_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    # \"time_budget\": 120,  # in seconds\n",
    "    \"metric\": \"rmse\", #\"r2\",\n",
    "    \"task\": \"regression\",\n",
    "    \"log_file_name\": \"reg_v1.log\",\n",
    "    \"max_iter\": 500,\n",
    "    # \"ensemble\": {\n",
    "    #     \"final_estimator\": LogisticRegressionCV(),\n",
    "    #     \"passthrough\": False,\n",
    "    # },\n",
    "}\n",
    "\n",
    "# Train with labeled input data\n",
    "for name,chosen_idx in zip(good_names,good_cols):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y[chosen_idx], test_size=test_size, random_state=42\n",
    "    )\n",
    "    mlflow.set_tracking_uri(\"../models/mlruns\")\n",
    "    mlflow.set_experiment(f\"flaml-automl-{name}-full-reg\")\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.list_experiments()\n",
    "    # print(experiments)\n",
    "    exp_id = [\n",
    "        experiment.experiment_id\n",
    "        for experiment in experiments\n",
    "        if experiment.name == f\"flaml-automl-{name}-full-reg\"\n",
    "    ][0]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # print(run.info.experiment_id)\n",
    "        automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
    "        # mlflow.sklearn.log_model(automl,\"automl-quint\")\n",
    "        mlflow.log_param(key=\"best_model\", value=automl.best_estimator)\n",
    "        mlflow.log_params(automl.best_config)\n",
    "        mlflow.log_metric(\n",
    "            key=\"rmse\",\n",
    "            value=np.sqrt(mean_squared_error(y_test, automl.predict(X_test))),\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            key=\"r2_score\", value=r2_score(y_test, automl.predict(X_test))\n",
    "        )\n",
    "\n",
    "    preds = automl.predict(X_test)\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    scplot = sns.scatterplot(x=preds, y=y_test)\n",
    "    scplot.set_xlabel(\"Predicted\")\n",
    "    scplot.set_ylabel(\"True\")\n",
    "    scplot.set_title(chosen_idx)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full NGA survey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data = pd.read_csv(\n",
    "    \"/Users/johnf/Downloads/raw_low_res_dssg/dhs/clean_nga_dhs.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[\"dep_sev_idx\"] = full_nga_data[\"sumpoor_sev\"] / (\n",
    "    6 - full_nga_data[sev_cols].drop(columns=[\"sumpoor_sev\"]).isna().sum(axis=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(np.log(full_nga_data.groupby('hex_code').dep_sev_idx.mean()+1),bins=20,kde=False)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "sns.distplot(full_nga_data.groupby(\"hex_code\").dep_sev_idx.mean(), bins=20, kde=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.features.build_features import boruta_shap_ftr_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subX_train = boruta_shap_ftr_select(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    plot=True,\n",
    "    n_trials=100,\n",
    "    sample=False,\n",
    "    train_or_test=\"test\",\n",
    "    normalize=True,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*subX_train.columns, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subX_test = X_test[[col for col in subX_train.columns]]\n",
    "submodel, subloss = baseline.lgbmreg_optunaCV(\n",
    "    subX_train,\n",
    "    subX_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    target_name=chosen_idx,\n",
    "    experiment_name=f\"lgbm-opt-{chosen_idx}-sub\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scplot = sns.scatterplot(x=submodel.predict(subX_test), y=y_test)\n",
    "scplot.set_xlabel(f\"Predicted (subset): {chosen_idx}\")\n",
    "scplot.set_ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=model.predict(X_test), y=y_test)\n",
    "scplot.set_xlabel(f\"Predicted (full): {chosen_idx}\")\n",
    "scplot.set_ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full feature selection vis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.features.build_features import boruta_shap_ftr_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,chosen_idx in zip(good_names,good_cols):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y[chosen_idx], test_size=test_size, random_state=42\n",
    "    )\n",
    "\n",
    "    subX_train = boruta_shap_ftr_select(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        plot=True,\n",
    "        n_trials=100,\n",
    "        sample=False,\n",
    "        train_or_test=\"test\",\n",
    "        normalize=True,\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-stage modelling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflated_vals = {\n",
    "    \"housing\": [0],\n",
    "    \"water\": [0, 1],\n",
    "    \"sanitation\": [0, 1],\n",
    "    \"education\": [0, 1],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chosen_idx in good_idxs:\n",
    "    map_dict = {\n",
    "        i: val\n",
    "        for i, val in zip(\n",
    "            range(len(inflated_vals[chosen_idx])), inflated_vals[chosen_idx]\n",
    "        )\n",
    "    }\n",
    "    map_fn = lambda x: map_dict.get(x, len(inflated_vals[chosen_idx]))\n",
    "    Y[f\"{chosen_idx}_stg_cls\"] = (\n",
    "        Y[chosen_idx.join([\"dep_\", \"_sev\"])].apply(map_fn).astype(\"category\")\n",
    "    )\n",
    "    # print(f\"{col.mean()*100:.2f}% of {chosen_idx} are {inflated_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    # \"time_budget\": 120,  # in seconds\n",
    "    \"metric\": \"micro_f1\",\n",
    "    \"task\": \"classification\",\n",
    "    \"log_file_name\": \"stg1_v1.log\",\n",
    "    \"max_iter\": 500,\n",
    "    # \"ensemble\": {\n",
    "    #     \"final_estimator\": LogisticRegressionCV(),\n",
    "    #     \"passthrough\": False,\n",
    "    # },\n",
    "}\n",
    "# Train with labeled input data\n",
    "for chosen_idx in good_idxs:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y[f\"{chosen_idx}_stg_cls\"], test_size=test_size, random_state=42\n",
    "    )\n",
    "    mlflow.set_tracking_uri(\"../models/mlruns\")\n",
    "    mlflow.set_experiment(f\"flaml-automl-{chosen_idx}-stg1\")\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiments = client.list_experiments()\n",
    "    # print(experiments)\n",
    "    exp_id = [\n",
    "        experiment.experiment_id\n",
    "        for experiment in experiments\n",
    "        if experiment.name == f\"flaml-automl-{chosen_idx}-stg1\"\n",
    "    ][0]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # print(run.info.experiment_id)\n",
    "        automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
    "        # mlflow.sklearn.log_model(automl,\"automl-quint\")\n",
    "        mlflow.log_metric(\n",
    "            key=\"f1_score\",\n",
    "            value=f1_score(y_test, automl.predict(X_test), average=\"micro\"),\n",
    "        )\n",
    "\n",
    "    preds = automl.predict(X_test)\n",
    "    print(\n",
    "        class_rep(\n",
    "            y_test,\n",
    "            preds,\n",
    "        )\n",
    "    )\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    hmap = sns.heatmap(conf_mat(y_test, preds), annot=True, fmt=\"d\")\n",
    "    hmap.set_xlabel(\"Predicted\")\n",
    "    hmap.set_ylabel(\"True\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.predict_proba(X_test).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.models.inflated_vals_2stg import InflatedValsRegressor\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "automl_cls = AutoML()\n",
    "automl_reg = AutoML()\n",
    "automl_cls_settings = {\n",
    "    \"metric\": \"micro_f1\",\n",
    "    \"task\": \"classification\",\n",
    "    \"log_file_name\": \"stg1_cls.log\",\n",
    "    \"max_iter\": 500,\n",
    "    \"estimator_list\":[\"lgbm\", \"xgboost\"] # if want to try others, need to impute nans\n",
    "}\n",
    "automl_reg_settings = {\n",
    "    \"metric\": \"rmse\",\n",
    "    \"task\": \"regression\",\n",
    "    \"log_file_name\": \"stg2_reg.log\",\n",
    "    \"max_iter\": 500,\n",
    "    \"estimator_list\":[\"lgbm\", \"xgboost\"]\n",
    "}\n",
    "# infl_vals_reg = InflatedValsRegressor(LGBMClassifier(), LGBMRegressor())\n",
    "infl_vals_reg = InflatedValsRegressor(automl_cls, automl_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y[f\"dep_{chosen_idx}_sev\"], test_size=test_size, random_state=42\n",
    ")\n",
    "infl_vals_reg.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    inflated_vals=inflated_vals[chosen_idx],\n",
    "    cls_fit_kwargs=automl_cls_settings,\n",
    "    reg_fit_kwargs=automl_reg_settings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl_vals_reg.predict(X_test, weighted=True).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(y_test, infl_vals_reg.predict(X_test, weighted=True)))\n",
    "print(r2_score(y_test, infl_vals_reg.predict(X_test, weighted=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(infl_vals_reg.predict(X_test, weighted=True), y_test)\n",
    "plt.scatter(infl_vals_reg.predict(X_test), y_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lgbm = LGBMRegressor().fit(X_train, y_train)\n",
    "print(r2_score(y_test, base_lgbm.predict(X_test)))\n",
    "plt.scatter(base_lgbm.predict(X_test), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up as pipelines for different combs\n",
    "- With / without expanded data, possibly w data extrapolated in different ways\n",
    "- With / without GDP imputation of different kinds (simple / knn / rf etc.) \n",
    "- With / without standardisation (standard / robust etc.)\n",
    "- With / without target transformation (e.g. log / box-cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try KNN imputer, speak to Arpita about more sophisticated imputers later\n",
    "# resave w n_conflicts and \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=42)  \n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flaml import AutoML\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "\n",
    "set_config(display='diagram')\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "standardiser = StandardScaler()\n",
    "automl = AutoML()\n",
    "\n",
    "automl_pipeline = Pipeline([\n",
    "    (\"imputer\",imputer),\n",
    "    (\"standardiser\", standardiser),\n",
    "    (\"automl\", automl)\n",
    "])\n",
    "# automl_pipeline\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60,  # total running time in seconds\n",
    "    \"metric\": \"mse\",  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"task\": \"regression\",  # task type\n",
    "    \"estimator_list\": [\"xgboost\", \"catboost\", \"lgbm\"],\n",
    "    \"log_file_name\": f\"{comb_name}.log\",  # flaml log file\n",
    "    \"seed\": 42, # random seed\n",
    "}\n",
    "pipeline_settings = {\n",
    "    f\"automl__{key}\": value for key, value in automl_settings.items()\n",
    "}\n",
    "automl_pipeline.fit(X_train, y_train, **pipeline_settings)\n",
    "\n",
    "# get automl object back \n",
    "automl = automl_pipeline.steps[2][1]\n",
    "# Get the best config and best learner\n",
    "print('Best ML learner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "# plot basic feature importances  \n",
    "plt.barh(automl.feature_names_in_, automl.feature_importances_)\n",
    "\n",
    "# compute different metrics on test set \n",
    "\n",
    "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
    "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
    "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dssg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1782bcc73560fcc6b67876a5451350856d869ba7693416f130e3e93ce636f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
