{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import swifter\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import stc_unicef_cpi.data.process_geotiff as pg\n",
    "import h3.api.numpy_int as h3\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/johnf/Downloads/higher_res_dssg/\")\n",
    "tiff_dir = base_dir / \"500m_res\"\n",
    "econ_dir = base_dir / \"econ\"\n",
    "clean_base = base_dir / \"nga_clean_v2.csv\"\n",
    "rwi_path = base_dir / \"NGA_relative_wealth_index.csv\"\n",
    "comm_zns = base_dir / \"commuting-zones-bdrys.csv\"\n",
    "connectivity_dir = base_dir / \"connectivity\"\n",
    "fb_conn = connectivity_dir / \"fb_nigeria.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen rows for model training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.array([\"all\", \"nigeria\", \"senegal\"])\n",
    "c2 = np.array([\"normal\", \"stratified\", \"spatial\"])\n",
    "c3 = np.array([\"all\", \"health\", \"nutrition\",\"av-3-prevalence\",\n",
    "            \"av-4-prevalence\",])\n",
    "c4 = np.array([\"none\", \"mean\", \"median\", \"knn\", \"linear\", \"rf\"])\n",
    "c5 = np.array([\"none\", \"standard\", \"minmax\", \"robust\"])\n",
    "c6 = np.array([\"none\", \"log\", \"power\"])\n",
    "c7 = np.array([\"normal\", \"stratified\", \"spatial\"])\n",
    "c8 = np.array([\" \", \"-ip\"])\n",
    "c9 = np.array([\" \", \"-univ\"])\n",
    "c10 = np.array([\" \", \"-cp2nbr\"])\n",
    "\n",
    "np.array(np.meshgrid(c1, c2, c3, c4, c5, c6, c7, c8, c9, c10)).T.reshape(-1, 10)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial CV tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.data.cv_loaders import cv_split  \n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "nga = world[world.name == \"Nigeria\"].geometry.__geo_interface__['features'][0]['geometry']\n",
    "nga_hex = h3.polyfill(nga,res=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/johnf/Downloads/higher_res_dssg/\")\n",
    "all_data = base_dir / \"clean_nga_w_autov1.csv\"\n",
    "thr_data = base_dir / \"nga_clean_v2_thr30.csv\"\n",
    "all_df = pd.read_csv(all_data)\n",
    "all_df[\"name_commuting_zone\"] = all_df[\"name_commuting_zone\"].astype(\"category\")\n",
    "thr_df = pd.read_csv(thr_data)\n",
    "thr_all = all_df.set_index(\"hex_code\").loc[thr_df.hex_code].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "k = 10\n",
    "N = 1000\n",
    "samp_hex = np.random.choice(thr_all[\"hex_code\"], size=N, replace=False)\n",
    "labels = np.random.rand(N)\n",
    "folds = cv_split(samp_hex, labels=labels, k=k, mode=\"spatial\")\n",
    "# sns.distplot(folds,kde=False, bins=k)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "latlongs = np.array([h3.h3_to_geo(hex) for hex in samp_hex])\n",
    "for _, test_idxs in folds:\n",
    "    ax.scatter(latlongs[test_idxs, 1], latlongs[test_idxs, 0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.data.cv_loaders import HexSpatialKFold\n",
    "\n",
    "latlongs = np.array([h3.h3_to_geo(hex) for hex in samp_hex])\n",
    "for train_idx, test_idx in HexSpatialKFold().split(samp_hex, labels):\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    ax.scatter(latlongs[train_idx, 1], latlongs[train_idx, 0], c=\"g\")\n",
    "    ax.scatter(latlongs[test_idx, 1], latlongs[test_idx, 0], c=\"r\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# from dask.delayed import delayed\n",
    "# parts = delayed(pd.read_excel)(connectivity_dir / 'cell_tower_nga.xlsx',\n",
    "#                                     sheet_name=0)\n",
    "# df = dd.from_delayed(parts)\n",
    "nga_cell_df = pd.read_excel(connectivity_dir / \"cell_tower_nga.xlsx\", sheet_name=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df.head()\n",
    "# will just want radio (generation category - want counts / cell if possible)\n",
    "# and possibly avg_signal, though generally 0\n",
    "# Most likely just overall count will be most useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df[\"hex_code\"] = nga_cell_df[[\"lat\", \"long\"]].swifter.apply(\n",
    "    lambda x: h3.geo_to_h3(x[0], x[1], resolution=7), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df = nga_cell_df[[\"hex_code\", \"radio\", \"avg_signal\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df.groupby([\"hex_code\", \"radio\"]).size().unstack(level=1).fillna(0).join(\n",
    "    nga_cell_df.groupby(\"hex_code\").avg_signal.mean()\n",
    ").to_csv(connectivity_dir / \"nga_cell_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "\n",
    "# speed_df = dd.read_csv(connectivity_dir/\"speedtest_world.csv\",blocksize=25e6).set_index(\"Unnamed: 0\")  # 25MB chunks\n",
    "speed_df = pd.read_csv(Path('../data/external/connectivity') / \"2021-10-01_performance_mobile_tiles.csv\")\n",
    "# speed_df[\"geometry\"] = speed_df.geometry.swifter.apply(shapely.wkt.loads)\n",
    "ctry = \"Nigeria\" \n",
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "ctry = world[world.name == ctry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df.geometry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt version\n",
    "bd_series = speed_df.geometry.str.replace(\"POLYGON\\s\\(+|\\)\",\"\").str.split(r\"\\s|,\\s\")\n",
    "speed_df['min_x'] = bd_series.str[1].astype('float')\n",
    "speed_df['max_y'] = bd_series.str[-1].astype('float')\n",
    "minx, miny, maxx, maxy = ctry.bounds.values.T.squeeze()\n",
    "res_df = speed_df[speed_df.min_x.between(minx-1e-2,maxx+1e-2)&speed_df.max_y.between(miny-1e-2,maxy+1e-2)].copy()\n",
    "res_df['geometry'] = res_df.geometry.swifter.apply(shapely.wkt.loads)\n",
    "res_df = gpd.GeoDataFrame(res_df, crs=\"epsg:4326\")\n",
    "\n",
    "nga_speed_df = gpd.sjoin(\n",
    "    res_df, ctry, how=\"inner\", op=\"intersects\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original version \n",
    "speed_df[\"geometry\"] = speed_df.geometry.swifter.apply(shapely.wkt.loads)\n",
    "speed_df = gpd.GeoDataFrame(speed_df, crs=\"epsg:4326\")\n",
    "nga_speed_df = gpd.sjoin(\n",
    "    speed_df, ctry, how=\"inner\", op=\"intersects\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def centroid_lat_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return shapely.wkt.loads(wkt_str).centroid.coords.xy[1]\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.nan\n",
    "# def centroid_long_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return shapely.wkt.loads(wkt_str).centroid.coords.xy[0]\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.nan\n",
    "\n",
    "# def centroid_latlong_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return np.array(shapely.wkt.loads(wkt_str).centroid.coords.xy).flatten()\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.array([np.nan,np.nan])\n",
    "\n",
    "# # speed_df['lat'] = speed_df.geometry.apply(centroid_lat_from_shply, meta=('geometry', float))\n",
    "# # speed_df['long'] = speed_df.geometry.apply(centroid_long_from_shply, meta=('geometry', float))\n",
    "# # speed_df[['lat','long']] = speed_df.geometry.swifter.apply(centroid_latlong_from_shply)\n",
    "# speed_df['lat'] = speed_df.geometry.swifter.apply(centroid_lat_from_shply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nga_speed_df.geometry.swifter.apply(\n",
    "    lambda x: pd.Series(np.array(x.centroid.coords.xy).flatten())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df[[\"long\", \"lat\"]] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df[\"hex_code\"] = nga_speed_df[[\"lat\", \"long\"]].swifter.apply(\n",
    "    lambda row: h3.geo_to_h3(row[0], row[1], 7), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df.to_csv(connectivity_dir / \"speedtest_nga.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df = pd.read_csv(connectivity_dir / \"nga_cell_clean.csv\")\n",
    "nga_speed_df = pd.read_csv(connectivity_dir / \"speedtest_nga.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nga_speed_df.long, nga_speed_df.lat)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df = (\n",
    "    nga_speed_df[\n",
    "        [\"hex_code\", \"avg_d_kbps\", \"avg_u_kbps\", \"avg_lat_ms\", \"tests\", \"devices\"]\n",
    "    ]\n",
    "    .groupby(\"hex_code\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"avg_d_kbps\": \"mean\",\n",
    "            \"avg_u_kbps\": \"mean\",\n",
    "            \"avg_lat_ms\": \"mean\",\n",
    "            \"tests\": \"sum\",\n",
    "            \"devices\": \"sum\",\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df = nga_df.join(\n",
    "    nga_cell_df.set_index(\"hex_code\"), on=[\"hex_code\"], how=\"left\"\n",
    ").join(nga_speed_df, on=\"hex_code\", how=\"left\")\n",
    "# new_nga_df.iloc[:, 92:].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df.n_conflicts.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject CISI data and add in again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stc_unicef_cpi.data import process_geotiff as pg\n",
    "\n",
    "cisi_dir = Path(\"/Users/johnf/Downloads/higher_res_dssg/CISI/010_degree\")\n",
    "pg.clip_tif_to_ctry(\n",
    "    \"/Users/johnf/Downloads/higher_res_dssg/CISI/010_degree/global.tif\",\n",
    "    ctry_name=\"Senegal\",\n",
    "    save_dir=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.rxr_reproject_tiff_to_target(\n",
    "    base_dir / \"Nigeria_africa_cisi.tif\",\n",
    "    tiff_dir / \"cpiPopData_500.tif\",\n",
    "    dest_path=base_dir / \"nga_cisi.tif\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = pg.agg_tif_to_df(\n",
    "    new_nga_df, base_dir / \"nga_cisi.tif\", rm_prefix=\"nga_\", verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df.drop(columns=[\"cii\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fill_cols = [\n",
    "    \"n_conflicts\",\n",
    "    \"GSM\",\n",
    "    \"LTE\",\n",
    "    \"NR\",\n",
    "    \"UMTS\",\n",
    "    \"tests\",\n",
    "    \"devices\",\n",
    "]\n",
    "alt_nga_df.fillna(value={col: 0 for col in zero_fill_cols}, inplace=True)\n",
    "alt_nga_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = pg.agg_tif_to_df(\n",
    "    alt_nga_df, tiff_dir / \"cpiHealthAccData_500.tif\", verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoh7 = pd.read_csv(base_dir / \"autoencoder_highres7.csv\", index_col=0)\n",
    "autol7 = pd.read_csv(base_dir / \"autoencoder_lowres7.csv\", index_col=0)\n",
    "autoh7.columns = [f\"auto_h{i}\" for i in range(len(autoh7.columns))]\n",
    "autol7.columns = [f\"auto_l{i}\" for i in range(len(autol7.columns))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = alt_nga_df.join(autoh7, on=\"hex_code\", how=\"left\").join(\n",
    "    autol7, on=\"hex_code\", how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_df = pd.read_csv(base_dir / \"nga_clean_justnewcomm_zns.csv\")[\n",
    "    [\n",
    "        \"hex_code\",\n",
    "        \"name_commuting_zone\",\n",
    "        \"population_commuting\",\n",
    "        \"road_len_commuting\",\n",
    "        \"area_commuting\",\n",
    "    ]\n",
    "]\n",
    "if commute_df.columns[1] in alt_nga_df:\n",
    "    alt_nga_df.drop(columns=commute_df.columns.tolist()[1:], inplace=True)\n",
    "alt_nga_df = alt_nga_df.join(\n",
    "    commute_df.set_index(\"hex_code\"), on=\"hex_code\", how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df.to_csv(base_dir / \"clean_nga_w_autov1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try mapping data to neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data = pd.read_csv(\n",
    "    \"/Users/johnf/Downloads/raw_low_res_dssg/dhs/clean_nga_dhs.csv\"\n",
    ")\n",
    "# Create variables for two or more deprivations\n",
    "for k in range(2, 5):\n",
    "    full_nga_data[f\"dep_{k}_or_more_sev\"] = full_nga_data[\"sumpoor_sev\"] >= k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nga_df.LONGNUM, nga_df.LATNUM, c=nga_df.location)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.location.astype(\"category\").describe()\n",
    "# 1 is urban, 2 is rural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[\"hex_incl_nbrs\"] = full_nga_data[[\"location\", \"hex_code\"]].apply(\n",
    "    lambda row: h3.k_ring(row[\"hex_code\"], 1)\n",
    "    if row[\"location\"] == 1\n",
    "    else h3.k_ring(row[\"hex_code\"], 2),\n",
    "    axis=1,\n",
    ")  # h3.hex_ring for hollow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols = [col for col in full_nga_data.columns if \"_sev\" in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [\n",
    "    col\n",
    "    for col in full_nga_data.columns\n",
    "    if (\n",
    "        \"int\" in str(full_nga_data[col].dtype)\n",
    "        or \"float\" in str(full_nga_data[col].dtype)\n",
    "    )\n",
    "]\n",
    "agg_dict = {col: \"mean\" for col in other_cols}\n",
    "agg_dict.update({idx: [\"mean\", \"count\"] for idx in sev_cols})\n",
    "# agg_dict.update({\"hhid\": \"count\"})\n",
    "new_df = (\n",
    "    full_nga_data.explode(\"hex_incl_nbrs\").groupby(by=[\"hex_incl_nbrs\"]).agg(agg_dict)\n",
    ")\n",
    "new_df.columns = [\"_\".join(col) for col in new_df.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(\n",
    "    columns={\n",
    "        f\"{sev}_mean\": f\"{sev.replace('dep_','').replace('_sev','')}_prev\"\n",
    "        for sev in sev_cols\n",
    "        if sev != \"deprived_sev\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "new_df.rename(\n",
    "    columns={\n",
    "        f\"{sev}_count\": f\"{sev.replace('dep_','').replace('_sev','')}_count\"\n",
    "        for sev in sev_cols\n",
    "        if sev != \"deprived_sev\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df.sumpoor_count >= 30].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(columns=['hex_code_mean'],inplace=True) \n",
    "new_df.rename(columns={'hex_incl_nbrs':'hex_code'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../data/processed/expanded_nigeria_res7_thres30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(base_dir / \"nga_clean_expanded.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(base_dir / \"nga_clean_expanded.csv\")\n",
    "new_df[new_df[\"nutrition_count\"] >= 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols = [col for col in full_nga_data.columns if \"sev\" in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[\"ndeps_missing\"] = full_nga_data[sev_cols].isna().sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((6 - full_nga_data[\"ndeps_missing\"] - full_nga_data[\"sumpoor_sev\"]) < 0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.ndeps_missing.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[sev_cols].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.age.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs all training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3.api.numpy_int as h3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_level = 3\n",
    "for col in sev_cols:\n",
    "    full_nga_data[f\"hex_code{res_level}\"] = full_nga_data[[\"LATNUM\", \"LONGNUM\"]].apply(\n",
    "        lambda row: h3.geo_to_h3(*row.values, res_level), axis=1\n",
    "    )\n",
    "    count_df = full_nga_data.groupby(f\"hex_code{res_level}\")[col].count()\n",
    "    _, bins = pd.qcut(count_df, [0, 0.05, 1.0], retbins=True)\n",
    "    # print(f\"5% cutoff for {col} is at {bins[1]}\")\n",
    "    if bins[1] < 30:\n",
    "        quants = pd.cut(count_df, [0, 30, np.inf])\n",
    "        cut_prop = quants.value_counts().sort_index().values[0] / len(count_df)\n",
    "        print(f\"Warning: cutoff at 30 for {col} removes {cut_prop*100:.2f}% of data\")\n",
    "        print(f\"5% cutoff is at {bins[1]}\")\n",
    "        for thresh in [5, 10, 15, 20]:\n",
    "            quants = pd.cut(count_df, [0, thresh, np.inf])\n",
    "            cut_prop = quants.value_counts().sort_index().values[0] / len(count_df)\n",
    "            print(f\"Cutoff at {thresh} for {col} removes {cut_prop*100:.2f}% of data\")\n",
    "# count_df.hist(bins=100)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_df = nga_df.loc[count_df.values >= 30].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_df.to_csv(clean_base.parent / \"nga_clean_v2_thr30.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First add higher res TIFF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pg.agg_tif_to_df(\n",
    "    nga_df,\n",
    "    tiff_dir,\n",
    "    rm_prefix=\"cpi\",\n",
    "    agg_fn=np.mean,\n",
    "    max_records=int(1e5),\n",
    "    replace_old=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_cols = [col for col in nga_df.columns if \"Data_500\" in col]\n",
    "old_cols = [col for col in merge_cols if col.rstrip(\"Data_500\") in nga_df.columns]\n",
    "nga_df.drop(columns=old_cols, inplace=True)\n",
    "nga_df.rename(columns={col: col.rstrip(\"Data_500\") for col in merge_cols}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "nga_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add econ TIFF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "econ_tiffs = glob.glob(str(econ_dir / \"*.tif\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_tiffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Convert econ tiffs to right resolution + CRS, rewrite to high_res dir\n",
    "for i, econ_tiff in enumerate(econ_tiffs):\n",
    "    with rxr.open_rasterio(econ_tiff) as data:\n",
    "        name = Path(econ_tiff).name\n",
    "        if \"GDP_PPP\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"GDP_PPP_1990\", \"GDP_PPP_2000\", \"GDP_PPP_2015\"]\n",
    "        elif \"2019GDP\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"GDP_2019\"]\n",
    "        elif \"EC\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"EC_2019\"]\n",
    "        data.rio.to_raster(econ_tiff)\n",
    "    pg.rxr_reproject_tiff_to_target(\n",
    "        econ_tiff,\n",
    "        glob.glob(str(tiff_dir / \"*.tif\"))[0],\n",
    "        tiff_dir / Path(econ_tiff).name,\n",
    "        verbose=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_econ_tifs = [\n",
    "    name\n",
    "    for name in glob.glob(str(tiff_dir / \"*.tif\"))\n",
    "    if \"GDP\" in Path(name).name or \"EC\" in Path(name).name\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_econ_tifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pg.agg_tif_to_df(\n",
    "    nga_df,\n",
    "    high_res_econ_tifs,\n",
    "    rm_prefix=\"Nigeria_\",\n",
    "    agg_fn=np.mean,\n",
    "    max_records=int(1e5),\n",
    "    replace_old=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add commuter zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "commzns_df = pd.read_csv(comm_zns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "commzns_df[\"geometry\"] = commzns_df[\"geometry\"].apply(wkt.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commzns_df = gpd.GeoDataFrame(commzns_df, crs=\"epsg:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commzns_df[commzns_df[\"country\"] == \"Nigeria\"].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: decide if will add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add FB connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(base_dir / \"clean_nga_w_autov1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df = pd.read_csv(fb_conn)\n",
    "conn_gdf = gpd.GeoDataFrame(\n",
    "    conn_df, geometry=gpd.points_from_xy(conn_df.long, conn_df.lat)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df[\"hex_code\"] = conn_df[[\"lat\", \"long\"]].swifter.apply(\n",
    "    lambda row: h3.geo_to_h3(row[0], row[1], resolution=7), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = nga_df.join(conn_df.set_index(\"hex_code\")[\"estimate_dau\"], on=\"hex_code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(base_dir / \"clean_nga_w_autov1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    *sorted(\n",
    "        [\n",
    "            (name, val)\n",
    "            for name, val in zip(\n",
    "                nga_df.isna().sum(axis=0).index, nga_df.isna().sum(axis=0).values\n",
    "            )\n",
    "        ],\n",
    "        key=lambda x: x[1],\n",
    "    ),\n",
    "    sep=\"\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for inside train set - worth including or not extensible?\n",
    "conn_gdf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally add RWI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquadkey2 import quadkey as qk\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# qk.QuadKey()\n",
    "top_left = qk.TileAnchor.ANCHOR_NW\n",
    "top_right = qk.TileAnchor.ANCHOR_NE\n",
    "bottom_right = qk.TileAnchor.ANCHOR_SE\n",
    "bottom_left = qk.TileAnchor.ANCHOR_SW\n",
    "getattr(qk.TileAnchor, bottom_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = \"010302121\"\n",
    "square = [\n",
    "    qk.from_str(test_idx).to_geo(anchor=point)\n",
    "    for point in [top_left, top_right, bottom_right, bottom_left]\n",
    "]\n",
    "square = Polygon(square)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3.api.numpy_int as h3\n",
    "\n",
    "ex_idx = h3.geo_to_h3(*square.boundary.coords[0], resolution=6)\n",
    "hex = Polygon(h3.h3_to_geo_boundary(ex_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create intersection and calculate percentage intersection based on areas\n",
    "intersection = hex.intersection(square)\n",
    "percent_area = intersection.area / square.area * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new target columns of proportion w > k deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(base_dir / \"clean_nga_w_autov1.csv\")\n",
    "\n",
    "full_nga_data = pd.read_csv(\n",
    "    \"/Users/johnf/Downloads/raw_low_res_dssg/dhs/clean_nga_dhs.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2,5): \n",
    "    full_nga_data[f\"dep_{k}_or_more_sev\"] = full_nga_data['sumpoor_sev'] >= k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_or_more_df = full_nga_data.groupby(by=[\"hex_code\"]).agg({col:np.mean for col in full_nga_data.columns if 'or_more' in col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_or_more_df.melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "for k in range(2,5): \n",
    "    fig,ax = plt.subplots(dpi=200)\n",
    "    # sns.histplot(data=k_or_more_df.melt(),x=\"value\",hue=\"variable\",element=\"step\", fill=False, kde=True)\n",
    "    sns.histplot(data=k_or_more_df[f\"dep_{k}_or_more_sev\"],element=\"step\", fill=False, kde=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these columns\n",
    "nga_df = nga_df.join(k_or_more_df,on=\"hex_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns so targets in right place\n",
    "cols = nga_df.columns.tolist()\n",
    "cols = cols[:20] + cols[-3:] + cols[20:-3]\n",
    "nga_df = nga_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(base_dir / \"clean_nga_w_autov1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see proportion of these targets that are non-zero \n",
    "# can see that 2 or more deprivation prevalence is a reasonable target, but not 3 or more\n",
    "# as ~50% or more of the data is just zero \n",
    "(k_or_more_df!=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check output of make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "nga = world[world.name == \"Nigeria\"].geometry.__geo_interface__[\"features\"][0][\n",
    "    \"geometry\"\n",
    "]\n",
    "nga_hex = h3.polyfill(nga, res=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def get_new_nbrs_at_k(hexes,k): \n",
    "    def hex_nbrs_at_k(hex,k): \n",
    "        return np.array(list(chain.from_iterable([h3.hex_ring(hex,dist) for dist in range(1,k+1)])))\n",
    "    nbrs_at_k = pd.DataFrame(hexes,columns=[\"hex_code\"]).hex_code.swifter.apply(lambda hex: hex_nbrs_at_k(hex,k)) \n",
    "    return np.setdiff1d(np.array(list(chain.from_iterable(nbrs_at_k))),hexes)\n",
    "    \n",
    "k = 2\n",
    "# ctry[f\"nbrs_at_{k}\"] = ctry.hex_code.swifter.apply(lambda hex: hex_nbrs_at_k(hex,k))\n",
    "len(get_new_nbrs_at_k(ctry.hex_code,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nbrs= np.setdiff1d(np.array(list(chain.from_iterable(ctry[f\"nbrs_at_{k}\"]))),ctry.hex_code.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dir = Path(\"../data/interim/\")\n",
    "df = pd.read_csv(int_dir / 'hexes_nigeria_res7_thres30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fill_cols = [\n",
    "    \"n_conflicts\",\n",
    "    \"GSM\",\n",
    "    \"LTE\",\n",
    "    \"NR\",\n",
    "    \"UMTS\",\n",
    "]\n",
    "df.fillna(value={col: 0 for col in zero_fill_cols}, inplace=True)\n",
    "df.head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(int_dir / 'hexes_nigeria_res7_thres30.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "survey_idx = cols.index(\"survey\")\n",
    "cols = cols[:survey_idx] + cols[-2:] + cols[survey_idx:-2] \n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ = int_dir / \"tmp_nigeria_econ.csv\" \n",
    "econ = pd.read_csv(econ,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gee = int_dir / \"tmp_nigeria_gee.csv\" \n",
    "gee = pd.read_csv(gee,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"../data/predictions\")\n",
    "preds = pd.read_csv(output_dir / \"preds_nigeria_res7.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlongs = preds.hex_code.swifter.apply(lambda x: h3.h3_to_geo(x))\n",
    "preds[\"lat\"] = latlongs.str[0]\n",
    "preds[\"long\"] = latlongs.str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "N = 10000\n",
    "subset = preds.iloc[:N]\n",
    "fig,ax = plt.subplots(dpi=200)\n",
    "sns.scatterplot(data=subset,x=subset['long'],y=subset['lat'],hue=subset['sumpoor_sev']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dssg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1782bcc73560fcc6b67876a5451350856d869ba7693416f130e3e93ce636f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
