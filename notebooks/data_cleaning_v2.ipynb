{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import swifter\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import stc_unicef_cpi.data.process_geotiff as pg\n",
    "import h3.api.numpy_int as h3\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/johnf/Downloads/higher_res_dssg/\")\n",
    "tiff_dir = base_dir / \"500m_res\"\n",
    "econ_dir = base_dir / \"econ\"\n",
    "connectivity_dir = base_dir / \"connectivity\"\n",
    "clean_base = base_dir / \"nga_clean_v2.csv\"\n",
    "rwi_path = base_dir / \"NGA_relative_wealth_index.csv\"\n",
    "comm_zns = base_dir / \"commuting-zones-bdrys.csv\"\n",
    "fb_conn = connectivity_dir / \"fb_nigeria.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB nga has lats between 4.2 and 13.9, longs between 2.6 and 14.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# from dask.delayed import delayed\n",
    "# parts = delayed(pd.read_excel)(connectivity_dir / 'cell_tower_nga.xlsx',\n",
    "#                                     sheet_name=0)\n",
    "# df = dd.from_delayed(parts)\n",
    "nga_cell_df = pd.read_excel(connectivity_dir / \"cell_tower_nga.xlsx\", sheet_name=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df.head()\n",
    "# will just want radio (generation category - want counts / cell if possible)\n",
    "# and possibly avg_signal, though generally 0\n",
    "# Most likely just overall count will be most useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df[\"hex_code\"] = nga_cell_df[[\"lat\", \"long\"]].swifter.apply(\n",
    "    lambda x: h3.geo_to_h3(x[0], x[1], resolution=7), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df = nga_cell_df[[\"hex_code\", \"radio\", \"avg_signal\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df.groupby([\"hex_code\", \"radio\"]).size().unstack(level=1).fillna(0).join(\n",
    "    nga_cell_df.groupby(\"hex_code\").avg_signal.mean()\n",
    ").to_csv(connectivity_dir / \"nga_cell_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "\n",
    "# speed_df = dd.read_csv(connectivity_dir/\"speedtest_world.csv\",blocksize=25e6).set_index(\"Unnamed: 0\")  # 25MB chunks\n",
    "speed_df = pd.read_csv(connectivity_dir / \"speedtest_world.csv\", index_col=0)\n",
    "speed_df[\"geometry\"] = speed_df.geometry.swifter.apply(shapely.wkt.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_df = gpd.GeoDataFrame(speed_df, crs=\"epsg:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "nga_speed_df = gpd.sjoin(\n",
    "    speed_df, world[world.name == \"Nigeria\"], how=\"inner\", op=\"intersects\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def centroid_lat_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return shapely.wkt.loads(wkt_str).centroid.coords.xy[1]\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.nan\n",
    "# def centroid_long_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return shapely.wkt.loads(wkt_str).centroid.coords.xy[0]\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.nan\n",
    "\n",
    "# def centroid_latlong_from_shply(wkt_str):\n",
    "#     try:\n",
    "#         return np.array(shapely.wkt.loads(wkt_str).centroid.coords.xy).flatten()\n",
    "#     except:\n",
    "#         # assume wkt reading error\n",
    "#         return np.array([np.nan,np.nan])\n",
    "\n",
    "# # speed_df['lat'] = speed_df.geometry.apply(centroid_lat_from_shply, meta=('geometry', float))\n",
    "# # speed_df['long'] = speed_df.geometry.apply(centroid_long_from_shply, meta=('geometry', float))\n",
    "# # speed_df[['lat','long']] = speed_df.geometry.swifter.apply(centroid_latlong_from_shply)\n",
    "# speed_df['lat'] = speed_df.geometry.swifter.apply(centroid_lat_from_shply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nga_speed_df.geometry.swifter.apply(\n",
    "    lambda x: pd.Series(np.array(x.centroid.coords.xy).flatten())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df[[\"long\", \"lat\"]] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df[\"hex_code\"] = nga_speed_df[[\"lat\", \"long\"]].swifter.apply(\n",
    "    lambda row: h3.geo_to_h3(row[0], row[1], 7), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df.to_csv(connectivity_dir / \"speedtest_nga.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_cell_df = pd.read_csv(connectivity_dir / \"nga_cell_clean.csv\")\n",
    "nga_speed_df = pd.read_csv(connectivity_dir / \"speedtest_nga.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_speed_df = (\n",
    "    nga_speed_df[\n",
    "        [\"hex_code\", \"avg_d_kbps\", \"avg_u_kbps\", \"avg_lat_ms\", \"tests\", \"devices\"]\n",
    "    ]\n",
    "    .groupby(\"hex_code\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"avg_d_kbps\": \"mean\",\n",
    "            \"avg_u_kbps\": \"mean\",\n",
    "            \"avg_lat_ms\": \"mean\",\n",
    "            \"tests\": \"sum\",\n",
    "            \"devices\": \"sum\",\n",
    "        }\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df = nga_df.join(nga_cell_df.set_index(\"hex_code\"), on=[\"hex_code\"]).join(\n",
    "    nga_speed_df\n",
    ")\n",
    "new_nga_df.iloc[:, 92:].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df.n_conflicts.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nga_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject CISI data and add in again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.clip_tif_to_ctry(base_dir / \"africa_cisi.tif\", save_dir=base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.rxr_reproject_tiff_to_target(\n",
    "    base_dir / \"Nigeria_africa_cisi.tif\",\n",
    "    tiff_dir / \"cpiPopData_500.tif\",\n",
    "    dest_path=base_dir / \"nga_cisi.tif\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = pg.agg_tif_to_df(new_nga_df,base_dir / \"nga_cisi.tif\",rm_prefix='nga_',verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df.drop(columns=['cii'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fill_cols = [\n",
    "    \"GSM\",\n",
    "    \"LTE\",\n",
    "    \"NR\",\n",
    "    \"UMTS\",\n",
    "    \"avg_signal\",\n",
    "    \"avg_d_kbps\",\n",
    "    \"avg_u_kbps\",\n",
    "    \"avg_lat_ms\",\n",
    "    \"tests\",\n",
    "    \"devices\",\n",
    "]\n",
    "alt_nga_df.fillna(value={col: 0 for col in zero_fill_cols}, inplace=True)\n",
    "alt_nga_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = pg.agg_tif_to_df(alt_nga_df,tiff_dir / \"cpiHealthAccData_500.tif\",verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoh7 = pd.read_csv(base_dir / \"autoencoder_highres7.csv\",index_col=0) \n",
    "autol7 = pd.read_csv(base_dir / \"autoencoder_lowres7.csv\",index_col=0)  \n",
    "autoh7.columns = [f'auto_h{i}' for i in range(len(autoh7.columns))]\n",
    "autol7.columns = [f'auto_l{i}' for i in range(len(autol7.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df = alt_nga_df.join(autoh7,on='hex_code').join(autol7,on='hex_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_df = pd.read_csv(base_dir / \"nga_clean_justnewcomm_zns.csv\")[\n",
    "    [\n",
    "        \"hex_code\",\n",
    "        \"name_commuting_zone\",\n",
    "        \"population_commuting\",\n",
    "        \"road_len_commuting\",\n",
    "        \"area_commuting\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "alt_nga_df = alt_nga_df.join(commute_df.set_index('hex_code'),on='hex_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_nga_df.to_csv(base_dir / \"clean_nga_w_autov1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try mapping data to neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data = pd.read_csv(\n",
    "    \"/Users/johnf/Downloads/raw_low_res_dssg/dhs/clean_nga_dhs.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nga_df.LONGNUM, nga_df.LATNUM, c=nga_df.location)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.location.astype(\"category\").describe()\n",
    "# 1 is urban, 2 is rural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[\"hex_incl_nbrs\"] = full_nga_data[[\"location\", \"hex_code\"]].apply(\n",
    "    lambda row: h3.k_ring(row[\"hex_code\"], 1)\n",
    "    if row[\"location\"] == 1\n",
    "    else h3.k_ring(row[\"hex_code\"], 2),\n",
    "    axis=1,\n",
    ")  # h3.hex_ring for hollow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols = [col for col in full_nga_data.columns if \"_sev\" in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [\n",
    "    col\n",
    "    for col in full_nga_data.columns\n",
    "    if (\n",
    "        \"int\" in str(full_nga_data[col].dtype)\n",
    "        or \"float\" in str(full_nga_data[col].dtype)\n",
    "    )\n",
    "]\n",
    "agg_dict = {col: \"mean\" for col in other_cols}\n",
    "agg_dict.update({idx: [\"mean\", \"count\"] for idx in sev_cols})\n",
    "# agg_dict.update({\"hhid\": \"count\"})\n",
    "new_df = (\n",
    "    full_nga_data.explode(\"hex_incl_nbrs\").groupby(by=[\"hex_incl_nbrs\"]).agg(agg_dict)\n",
    ")\n",
    "new_df.columns = [\"_\".join(col) for col in new_df.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(\n",
    "    columns={\n",
    "        f\"{sev}_mean\": f\"{sev.lstrip('dep_').rstrip('_sev')}_prev\"\n",
    "        for sev in sev_cols\n",
    "        if sev != \"deprived_sev\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "new_df.rename(\n",
    "    columns={\n",
    "        f\"{sev}_count\": f\"{sev.lstrip('dep_').rstrip('_sev')}_count\"\n",
    "        for sev in sev_cols\n",
    "        if sev != \"deprived_sev\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "new_df.rename(\n",
    "    columns={\"ucation_count\": \"education_count\", \"ucation_prev\": \"education_prev\"},\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head().columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(base_dir / \"nga_clean_expanded.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(base_dir / \"nga_clean_expanded.csv\")\n",
    "new_df[new_df[\"nutrition_count\"] >= 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols = [col for col in full_nga_data.columns if \"sev\" in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[\"ndeps_missing\"] = full_nga_data[sev_cols].isna().sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((6 - full_nga_data[\"ndeps_missing\"] - full_nga_data[\"sumpoor_sev\"]) < 0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.ndeps_missing.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data[sev_cols].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nga_data.age.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs all training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3.api.numpy_int as h3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_level = 3\n",
    "for col in sev_cols:\n",
    "    full_nga_data[f\"hex_code{res_level}\"] = full_nga_data[[\"LATNUM\", \"LONGNUM\"]].apply(\n",
    "        lambda row: h3.geo_to_h3(*row.values, res_level), axis=1\n",
    "    )\n",
    "    count_df = full_nga_data.groupby(f\"hex_code{res_level}\")[col].count()\n",
    "    _, bins = pd.qcut(count_df, [0, 0.05, 1.0], retbins=True)\n",
    "    # print(f\"5% cutoff for {col} is at {bins[1]}\")\n",
    "    if bins[1] < 30:\n",
    "        quants = pd.cut(count_df, [0, 30, np.inf])\n",
    "        cut_prop = quants.value_counts().sort_index().values[0] / len(count_df)\n",
    "        print(f\"Warning: cutoff at 30 for {col} removes {cut_prop*100:.2f}% of data\")\n",
    "        print(f\"5% cutoff is at {bins[1]}\")\n",
    "        for thresh in [5, 10, 15, 20]:\n",
    "            quants = pd.cut(count_df, [0, thresh, np.inf])\n",
    "            cut_prop = quants.value_counts().sort_index().values[0] / len(count_df)\n",
    "            print(f\"Cutoff at {thresh} for {col} removes {cut_prop*100:.2f}% of data\")\n",
    "# count_df.hist(bins=100)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_df = nga_df.loc[count_df.values >= 30].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_df.to_csv(clean_base.parent / \"nga_clean_v2_thr30.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First add higher res TIFF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pg.agg_tif_to_df(\n",
    "    nga_df,\n",
    "    tiff_dir,\n",
    "    rm_prefix=\"cpi\",\n",
    "    agg_fn=np.mean,\n",
    "    max_records=int(1e5),\n",
    "    replace_old=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_cols = [col for col in nga_df.columns if \"Data_500\" in col]\n",
    "old_cols = [col for col in merge_cols if col.rstrip(\"Data_500\") in nga_df.columns]\n",
    "nga_df.drop(columns=old_cols, inplace=True)\n",
    "nga_df.rename(columns={col: col.rstrip(\"Data_500\") for col in merge_cols}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "nga_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add econ TIFF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "econ_tiffs = glob.glob(str(econ_dir / \"*.tif\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_tiffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Convert econ tiffs to right resolution + CRS, rewrite to high_res dir\n",
    "for i, econ_tiff in enumerate(econ_tiffs):\n",
    "    with rxr.open_rasterio(econ_tiff) as data:\n",
    "        name = Path(econ_tiff).name\n",
    "        if \"GDP_PPP\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"GDP_PPP_1990\", \"GDP_PPP_2000\", \"GDP_PPP_2015\"]\n",
    "        elif \"2019GDP\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"GDP_2019\"]\n",
    "        elif \"EC\" in name:\n",
    "            data.attrs[\"long_name\"] = [\"EC_2019\"]\n",
    "        data.rio.to_raster(econ_tiff)\n",
    "    pg.rxr_reproject_tiff_to_target(\n",
    "        econ_tiff,\n",
    "        glob.glob(str(tiff_dir / \"*.tif\"))[0],\n",
    "        tiff_dir / Path(econ_tiff).name,\n",
    "        verbose=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_econ_tifs = [\n",
    "    name\n",
    "    for name in glob.glob(str(tiff_dir / \"*.tif\"))\n",
    "    if \"GDP\" in Path(name).name or \"EC\" in Path(name).name\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_econ_tifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pg.agg_tif_to_df(\n",
    "    nga_df,\n",
    "    high_res_econ_tifs,\n",
    "    rm_prefix=\"Nigeria_\",\n",
    "    agg_fn=np.mean,\n",
    "    max_records=int(1e5),\n",
    "    replace_old=True,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add commuter zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "commzns_df = pd.read_csv(comm_zns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "commzns_df[\"geometry\"] = commzns_df[\"geometry\"].apply(wkt.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commzns_df = gpd.GeoDataFrame(commzns_df, crs=\"epsg:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commzns_df[commzns_df[\"country\"] == \"Nigeria\"].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: decide if will add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now add FB connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(base_dir / \"clean_nga_w_autov1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df = pd.read_csv(fb_conn)\n",
    "conn_gdf = gpd.GeoDataFrame(\n",
    "    conn_df, geometry=gpd.points_from_xy(conn_df.long, conn_df.lat)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df['hex_code']=conn_df[['lat','long']].swifter.apply(lambda row: h3.geo_to_h3(row[0],row[1],resolution=7),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = nga_df.join(conn_df.set_index('hex_code')['estimate_dau'],on='hex_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(base_dir / \"clean_nga_w_autov1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for inside train set - worth including or not extensible?\n",
    "conn_gdf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally add RWI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df = pd.read_csv(clean_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquadkey2 import quadkey as qk\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# qk.QuadKey()\n",
    "top_left = qk.TileAnchor.ANCHOR_NW\n",
    "top_right = qk.TileAnchor.ANCHOR_NE\n",
    "bottom_right = qk.TileAnchor.ANCHOR_SE\n",
    "bottom_left = qk.TileAnchor.ANCHOR_SW\n",
    "getattr(qk.TileAnchor, bottom_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = \"010302121\"\n",
    "square = [\n",
    "    qk.from_str(test_idx).to_geo(anchor=point)\n",
    "    for point in [top_left, top_right, bottom_right, bottom_left]\n",
    "]\n",
    "square = Polygon(square)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3.api.numpy_int as h3\n",
    "\n",
    "ex_idx = h3.geo_to_h3(*square.boundary.coords[0], resolution=6)\n",
    "hex = Polygon(h3.h3_to_geo_boundary(ex_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create intersection and calculate percentage intersection based on areas\n",
    "intersection = hex.intersection(square)\n",
    "percent_area = intersection.area / square.area * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nga_df.to_csv(clean_base, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dssg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1782bcc73560fcc6b67876a5451350856d869ba7693416f130e3e93ce636f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
